{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据（取最小行数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1878 4\n"
     ]
    }
   ],
   "source": [
    "datalist = []\n",
    "min_rows = float('inf') \n",
    "\n",
    "for filename in os.listdir(\"/home/yichuan/ywc/meta-labeling/cryptocurrency\"):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(\"/home/yichuan/ywc/meta-labeling/cryptocurrency\", filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.drop(columns=[\"Date\"])\n",
    "        datalist.append(df.values)\n",
    "        min_rows = min(min_rows, df.shape[0])      \n",
    "\n",
    "data_list = [data[:min_rows] for data in datalist]\n",
    "\n",
    "print(min_rows,len(data_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理最后一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21791101  0.221791    0.214866    0.21748801  0.21748801 -2.28482287]\n",
      " [ 0.218256    0.21906801  0.20525999  0.20648301  0.20648301 -2.33154956]\n",
      " [ 0.205948    0.21445601  0.205459    0.21043     0.21043    -2.37803102]\n",
      " ...\n",
      " [ 0.36812201  0.368543    0.35613599  0.35653099  0.35653099 -0.58243597]\n",
      " [ 0.35652399  0.357225    0.338911    0.34284601  0.34284601 -0.51650078]\n",
      " [ 0.34283099  0.34531301  0.33533299  0.34501699  0.34501699 -0.80060086]]\n"
     ]
    }
   ],
   "source": [
    "def logVolume(X: np.ndarray):\n",
    "    volume = X[:, -1]  \n",
    "    volume_log = np.log(volume + 1)  \n",
    "\n",
    "    mean_log = np.mean(volume_log)  \n",
    "    std_log = np.std(volume_log)  \n",
    "\n",
    "    volume_std = (volume_log - mean_log) / std_log  \n",
    "\n",
    "    X[:, -1] = volume_std  \n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "for data in data_list:\n",
    "    data=logVolume(data)    \n",
    "\n",
    "print(data_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建标签函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "days=10\n",
    "\n",
    "ptsl = [0.05, 0.05]  \n",
    "return_min = 0.005\n",
    "def triple_barrier(close: np.ndarray, days=10, pts=[0.05, 0.05] ):\n",
    "    bin = np.zeros(close.size, dtype=int)  \n",
    "    for i in range(close.size):\n",
    "        for d in range(days):\n",
    "            index = min(i + d + 1, close.size - 1)  \n",
    "            if close[index] >= close[i] * (1 + ptsl[0]):  \n",
    "                bin[i] = 1\n",
    "                break\n",
    "            elif close[index] <= close[i] * (1 - ptsl[1]):  \n",
    "                bin[i] = -1\n",
    "                break\n",
    "    \n",
    "    return bin\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1878,)\n"
     ]
    }
   ],
   "source": [
    "binmat=np.full((min_rows, 4), 3)\n",
    "for i in range(4):\n",
    "    binmat[:,i]=triple_barrier(data_list[i][:,3])\n",
    "\n",
    "label=np.mean(binmat, axis=1)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1878, 6)\n",
      "(1878, 24)\n"
     ]
    }
   ],
   "source": [
    "# 确保所有二维数组具有相同的形状\n",
    "shapes = {data.shape for data in data_list}\n",
    "if len(shapes) > 1:\n",
    "    raise ValueError(\"所有 CSV 文件中的数据形状必须一致\")\n",
    "    \n",
    "dataset=np.array(data_list)\n",
    "print(dataset.shape)\n",
    "dataset = dataset.transpose(1, 0, 2).reshape(1878, -1)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary model with constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=(label + 1)/2\n",
    "targets=np.where(targets > 0.5, 1, 0)\n",
    "\n",
    "train_ratio = 0.8\n",
    "n_train = int(len(dataset) * train_ratio) \n",
    "X_train = dataset[:n_train]\n",
    "X_test = dataset[n_train:]\n",
    "y_train = targets[:n_train]\n",
    "y_test = targets[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asset_exposure_constraint(weights, max_exposure=0.5):\n",
    "    \"\"\"Ensure no asset weight exceeds max_exposure.\"\"\"\n",
    "    return all(abs(w) <= max_exposure for w in weights)\n",
    "\n",
    "def sector_diversification_constraint(weights, sector_mapping, min_sectors=2):\n",
    "    \"\"\"Ensure allocation spans at least min_sectors.\"\"\"\n",
    "    unique_sectors = set(sector_mapping[np.nonzero(weights)])\n",
    "    return len(unique_sectors) >= min_sectors\n",
    "\n",
    "\n",
    "def risk_tolerance_constraint(weights, cov_matrix, max_risk=0.05):\n",
    "    \"\"\"Ensure portfolio variance is within max_risk.\"\"\"\n",
    "    portfolio_variance = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "    #print(portfolio_variance)\n",
    "    return portfolio_variance <= max_risk\n",
    "\n",
    "def apply_constraints(weights, sector_mapping, cov_matrix):\n",
    "    \"\"\"Check all constraints.\"\"\"\n",
    "    return (\n",
    "        asset_exposure_constraint(weights, max_exposure=0.5) and\n",
    "        sector_diversification_constraint(weights, sector_mapping, min_sectors=2) and\n",
    "        risk_tolerance_constraint(weights, cov_matrix, max_risk=0.05)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary model using XGBoost\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_primary = model.predict(X_test)\n",
    "primary_signals = np.where(y_pred_primary > 0.5, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "376\n",
      "(376, 24)\n"
     ]
    }
   ],
   "source": [
    "print(primary_signals)\n",
    "print(len(primary_signals))\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1502, 24)\n",
      "(376, 24)\n",
      "(376,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376, 4)\n",
      "[[0.00975429 0.00216908 0.00084753 0.01012304]\n",
      " [0.00216908 0.06281248 0.01614855 0.00204031]\n",
      " [0.00084753 0.01614855 0.01446641 0.00049159]\n",
      " [0.01012304 0.00204031 0.00049159 0.02662378]]\n"
     ]
    }
   ],
   "source": [
    "# Assume asset returns, sector mapping, and covariance matrix as placeholders\n",
    "sector_mapping = np.array([1,2,3,4])\n",
    "\n",
    "Closelist=[]\n",
    "for filename in os.listdir(\"/home/yichuan/ywc/meta-labeling/cryptocurrency\"):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(\"/home/yichuan/ywc/meta-labeling/cryptocurrency\", filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[\"Adj Close\"]\n",
    "        Closelist.append(df.values)\n",
    "        min_rows = min(min_rows, df.shape[0])\n",
    "Closelist = [data[:min_rows] for data in Closelist]\n",
    "Close=np.array(Closelist).T\n",
    "Close_test=Close[sorted(indices_test),:]\n",
    "print(Close_test.shape)\n",
    "returns = (Close_test[1:] - Close_test[:-1]) / Close_test[:-1]  \n",
    "cov_matrix = np.cov(returns, rowvar=False)\n",
    "print(cov_matrix)\n",
    "\n",
    "asset_returns = np.random.normal(0.01, 0.02, size=dataset.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondary model (meta-labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Develop secondary model (meta-labeling) 二级模型，即meta-labeling\n",
    "# Create meta-labels for secondary model training\n",
    "meta_labels = primary_signals == y_test\n",
    "t_indices = np.arange(len(X_test))\n",
    "X_train_meta, X_test_meta, y_train_meta, y_test_meta, t_indices_train, t_indices_test = train_test_split(\n",
    "    X_test, meta_labels, t_indices, test_size=0.5, random_state=42\n",
    ")\n",
    "X_test_meta = pd.DataFrame(X_test_meta)\n",
    "\n",
    "\n",
    "# Train and test secondary model (meta-labeling) 训练模型并生成二级信号\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train_meta, y_train_meta)\n",
    "y_pred_secondary = logistic.predict(X_test_meta)\n",
    "\n",
    "\n",
    "# Step 4: Filtering, denoising, and refining signals 进行信号过滤，生成最终信号\n",
    "refined_signals = primary_signals.copy()\n",
    "zero_pred_mask = (y_pred_secondary == 0)\n",
    "meta_zero_indices = np.where(zero_pred_mask)[0]  \n",
    "original_test_indices = t_indices_test[meta_zero_indices]  \n",
    "#print(original_test_indices)\n",
    "for i in original_test_indices:\n",
    "    refined_signals[i] = (1-refined_signals[i])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 95\n",
      "(376,) [0 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0\n",
      " 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0\n",
      " 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(refined_signals),np.sum(abs(refined_signals-primary_signals)))\n",
    "print(refined_signals.shape,refined_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate modified(final) portfolio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample portfolio based on signals\n",
    "def construct_portfolio(signals, asset_returns, sector_mapping, cov_matrix):\n",
    "    \"\"\"Construct a portfolio based on signals and constraints.\"\"\"\n",
    "    weights = np.zeros((len(signals),4))\n",
    "    for i, signal in enumerate(signals):\n",
    "        if signal == 1:\n",
    "            # Placeholder: Assign random initial weights to activated signals\n",
    "            weights[i,:] = np.random.rand(4)\n",
    "            # Normalize weights\n",
    "            weights[i,:] /= np.sum(weights[i,:])\n",
    "            # Apply constraints\n",
    "            if apply_constraints(weights[i,:], sector_mapping, cov_matrix):\n",
    "                weights[i,:] = weights[i,:]\n",
    "                #print(\"Constraints good.\")\n",
    "            else:\n",
    "                #print(weights[i,:])\n",
    "                weights[i,:] = np.zeros_like(weights[i,:]) #adjust weights                \n",
    "                #print(\"Constraints not satisfied. Adjust weights.\")\n",
    "\n",
    "    return weights   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Portfolio Weights:\n",
      " [[0.         0.         0.         0.        ]\n",
      " [0.09242296 0.09180745 0.3784532  0.43731639]\n",
      " [0.47402466 0.22578809 0.15144127 0.14874598]\n",
      " ...\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "active trade days: 113 (376, 4)\n"
     ]
    }
   ],
   "source": [
    "final_portfolio_weights = construct_portfolio(refined_signals, asset_returns, sector_mapping, cov_matrix)\n",
    "tradedays=0\n",
    "# Output portfolio weights\n",
    "print(\"Final Portfolio Weights:\\n\", final_portfolio_weights)\n",
    "for i in range(final_portfolio_weights.shape[0]):\n",
    "    if np.sum(final_portfolio_weights[i]) !=0:\n",
    "        tradedays+=1\n",
    "print(\"active trade days:\",tradedays,final_portfolio_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Portfolio Weights:\n",
      " [[0.         0.         0.         0.        ]\n",
      " [0.09242296 0.09180745 0.3784532  0.43731639]\n",
      " [0.47402466 0.22578809 0.15144127 0.14874598]\n",
      " ...\n",
      " [0.04238762 0.3647698  0.25409255 0.33875003]\n",
      " [0.04238762 0.3647698  0.25409255 0.33875003]\n",
      " [0.04238762 0.3647698  0.25409255 0.33875003]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,final_portfolio_weights.shape[0]):\n",
    "    if np.all(final_portfolio_weights[i, :] == 0):\n",
    "        final_portfolio_weights[i,:]=final_portfolio_weights[i-1,:]\n",
    "\n",
    "print(\"Final Portfolio Weights:\\n\", final_portfolio_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio of the final weights: 1.0410\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_sharpe_ratio(folder_path, weights, m, n,risk_free_rate=0.0):\n",
    "    \n",
    "    files = sorted(os.listdir(folder_path))  \n",
    "    \n",
    "    \n",
    "    stock_data = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(folder_path, file)).iloc[m:n]        \n",
    "        stock_data.append(df['Close'].values)\n",
    "\n",
    "    stock_prices = np.column_stack(stock_data)\n",
    "\n",
    "    stock_returns = np.diff(stock_prices, axis=0) / stock_prices[:-1]\n",
    "\n",
    "    portfolio_returns = np.sum(stock_returns * weights, axis=1)  \n",
    "\n",
    "    mean_return = np.mean(portfolio_returns) * 365\n",
    "    volatility = np.std(portfolio_returns) * np.sqrt(365)\n",
    "\n",
    "    sharpe_ratio = (mean_return - risk_free_rate) / volatility\n",
    "    return sharpe_ratio\n",
    "\n",
    "\n",
    "folder_path = \"/home/yichuan/ywc/meta-labeling/cryptocurrency\"\n",
    "m = n_train - 1\n",
    "n = min_rows  \n",
    "\n",
    "sharpe_ratio = calculate_sharpe_ratio(folder_path, final_portfolio_weights, m, n,risk_free_rate=0.0)\n",
    "print(f\"Sharpe Ratio of the final weights: {sharpe_ratio:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ywc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
